<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tianye Li</title>
  
  <meta name="author" content="Tianye Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        
        <!-- Intro -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tianye Li</name>
              </p>
              <p>I am a <a href="http://phdcomics.com/">Ph.D.</a> candidate in <a href="https://www.cs.usc.edu/">Computer Science</a> at <a href="https://www.usc.edu/">USC</a>, advised by <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>. In summer and fall 2020, I am a research intern at the <a href="https://research.fb.com/category/augmented-reality-virtual-reality/">Facebook Reality Labs</a>. 
              </p>
              <p>
                In summer 2018, I was a research intern at <a href="https://www.snap.com/en-US/">Snap Inc.</a>, working with <a href="http://chongyangma.com/">Chongyang Ma</a> and <a href="http://linjieluo.com/">Linjie Luo</a>. From fall 2016 to spring 2017, I visited the <a href="https://ps.is.tuebingen.mpg.de/">Max Planck Institute for Intelligent Systems</a> (<a href="https://en.wikipedia.org/wiki/T%C3%BCbingen">TÃ¼bingen</a>), working with <a href="https://sites.google.com/site/bolkartt/">Timo Bolkart</a>, <a href="https://scholar.google.com/citations?user=Wx62iOsAAAAJ&hl=en">Javier Romero</a>, and <a href="https://ps.is.tuebingen.mpg.de/person/black">Michael J. Black</a>.
                I did my B.Eng. at the <a href="http://en.xidian.edu.cn/">Xidian University</a> and M.Sc. (with honor) at <a href="https://minghsiehece.usc.edu/">USC</a>, both in <a>Electrical Engineering</a>.
              </p>
              <p style="text-align:center">
                Email: &lt;first_name&gt; &lt;last_name&gt; <i>at</i> protonmail <i>dot</i> com
              </p>
              <p style="text-align:center">
                <a href="data/Tianye_Li_full_cv_20200709.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=ztIh4rgAAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/tianyeli.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/tianyeli.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- Research -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests are computer vision and computer graphics. Most of my work aim to analyze geometry and motion of human face and body, although I've also gained interests for general scenes and objects.
                <!-- Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- TPAMI 2020 differentiable rendering -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tpami20_softras.png" alt="tpami20" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <!-- <td width="75%" valign="middle"> -->
              <a href="https://ieeexplore.ieee.org/abstract/document/9134794">
                <papertitle>A General Differentiable Mesh Renderer for Image-based 3D Reasoning</papertitle>
              </a>
              <br>
              <a href="https://shichenliu.github.io/">Shichen Liu</a>,
              <strong>Tianye Li</strong>,
              <a href="http://chenweikai.github.io/">Weikai Chen</a>,
              <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>
              <br>
              <em>TPAMI 2020</em>
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9134794">paper</a> /
              <a href="">bibtex</a>
              <p>An extended version of <i>Soft Rasterizer</i>.</p>
            </td>
          </tr>

          <!-- ICCV 2019 differentiable rendering -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv19_softras.png" alt="iccv19_softras" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <!-- <td width="75%" valign="middle"> -->
              <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Soft_Rasterizer_A_Differentiable_Renderer_for_Image-Based_3D_Reasoning_ICCV_2019_paper.pdf">
                <papertitle>Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning</papertitle>
              </a>
              <br>
              <a href="https://shichenliu.github.io/">Shichen Liu</a>,
              <strong>Tianye Li</strong>,
              <a href="http://chenweikai.github.io/">Weikai Chen</a>,
              <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>
              <br>
              <em>ICCV 2019 <font color="red"><strong>(Oral Presentation)</strong></font></em>
              <br>
              <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Soft_Rasterizer_A_Differentiable_Renderer_for_Image-Based_3D_Reasoning_ICCV_2019_paper.pdf">paper</a> /
              <a href="https://github.com/ShichenLiu/SoftRas">code</a> /
              <a href="">bibtex</a>
              <p>A differentiable rasterization-based mesh renderer.</p>
            </td>
          </tr>

          <!-- ICCV 2019 face protrait undistortion -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv19_protrait_undist.png" alt="iccv19_protrait_undist" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <!-- <td width="75%" valign="middle"> -->
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhao_Learning_Perspective_Undistortion_of_Portraits_ICCV_2019_paper.pdf">
                <papertitle>Learning Perspective Undistortion of Portraits</papertitle>
              </a>
              <br>
              <a href="http://ict.usc.edu/profile/yajie-zhao/">Yajie Zhao</a>,
              <a href="https://zeng.science/">Zeng Huang</a>,
              <strong>Tianye Li</strong>,
              <a href="http://chenweikai.github.io/">Weikai Chen</a>,
              <a href="http://www.chloelegendre.com/">Chloe LeGendre</a>,
              <a href="">Xinglei Ren</a>,
              <a href="http://junxnui.github.io/">Jun Xing</a>,
              <a href="http://www.arishapiro.com/">Ari Shapiro</a>,
              <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>
              <br>
              <em>ICCV 2019 <font color="red"><strong>(Oral Presentation)</strong></font></em>
              <br>
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhao_Learning_Perspective_Undistortion_of_Portraits_ICCV_2019_paper.pdf">paper</a> /
              <a href="https://github.com/bearjoy730/Learning-Perspective-Undistortion-of-Portraits">project page</a> /
              <a href="">bibtex</a>
              <p>A system that corrects perspective distortion of face protrait.</p>
            </td>
          </tr>

          <!-- ECCV 2018 sparse view voluemtric capture -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eccv18_volume_capture.png" alt="eccv18" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <!-- <td width="75%" valign="middle"> -->
              <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Zeng_Huang_Deep_Volumetric_Video_ECCV_2018_paper.pdf">
                <papertitle>Deep Volumetric Video from Very Sparse Multi-View Performance Capture</papertitle>
              </a>
              <br>
              <a href="https://zeng.science/">Zeng Huang</a>,
              <strong>Tianye Li</strong>,
              <a href="http://chenweikai.github.io/">Weikai Chen</a>,
              <a href="http://ict.usc.edu/profile/yajie-zhao/">Yajie Zhao</a>,
              <a href="http://junxnui.github.io/">Jun Xing</a>,
              <a href="http://www.chloelegendre.com/">Chloe LeGendre</a>,
              <a href="http://linjieluo.com/">Linjie Luo</a>,
              <a href="http://chongyangma.com/">Chongyang Ma</a>,
              <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>
              <br>
              <em>ECCV 2018</em>
              <br>
              <a href="https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnx0aWFueWVmb2N1c3xneDoxMzg5OTQwODEzOTZmYjQ3">paper</a> /
              <a href="https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnx0aWFueWVmb2N1c3xneDo2ZjViNDQ5Nzc5Y2NmMzg2">supplemental</a> /
              <a href="https://www.youtube.com/watch?v=sQnXlQ3GyKc&feature=youtu.be">video</a> /
              <a href="https://www.dropbox.com/s/kl73b80xhe3bic3/ECCV18_Poster_final.pdf?dl=0">poster</a> /
              <a href="">bibtex</a>
              <p>A method for volumetric reconstruction given very sparse RGB camera views using implicit function representation.</p>
            </td>
          </tr>

          <!-- SIGGRAPH Asia 2017 FLAME face model -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/sigasia17_flame.png" alt="sigasia17" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <!-- <td width="75%" valign="middle"> -->
              <a href="https://dl.acm.org/doi/10.1145/3130800.3130813">
                <papertitle>Learning a Model of Facial Shape and Expression from 4D Scans</papertitle>
              </a>
              <br>
              <strong>Tianye Li</strong>*,
              <a href="https://sites.google.com/site/bolkartt/">Timo Bolkart</a>*,
              <a href="https://ps.is.tuebingen.mpg.de/person/black/">Michael J. Black</a>,
              <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>,
              <a href="https://ps.is.tuebingen.mpg.de/person/jromero">Javier Romero</a>
              <br>
              <em>SIGGRAPH Asia 2017</em>
              <br>
              <a href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/400/paper.pdf">paper</a> /
              <a href="https://ps.is.tuebingen.mpg.de/uploads_file/attachment/attachment/401/supplementary.pdf">supplemental</a> /
              <a href="https://youtu.be/36rPTkhiJTM">video</a> /
              <a href="https://youtu.be/kslTkzBKR1Q">fast-forward</a> /
              <a href="http://flame.is.tue.mpg.de/">model & data</a> /
              <a href="">bibtex</a>
              <p>A light-weight generic face model, <i>FLAME</i>, that is expressive to fit a wide range of identites, expressions and poses.</p>
            </td>
          </tr>

          <!-- ECCV 2016 face tracking -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eccv16_face_track.png" alt="eccv16" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <!-- <td width="75%" valign="middle"> -->
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-46484-8_15">
                <papertitle>Real-Time Facial Segmentation and Performance Capture from RGB Input</papertitle>
              </a>
              <br>
              <a href="http://www-scf.usc.edu/~saitos/">Shunsuke Saito</a>,
              <strong>Tianye Li</strong>,
              <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html">Hao Li</a>
              <br>
              <em>ECCV 2016</em>
              <br>
              <a href="http://www.hao-li.com/publications/papers/eccv2016RTFSPCRI.pdf">paper</a> /
              <a href="http://www.hao-li.com/publications/additionalMaterials/eccv2016additionalMaterials.pdf">supplemental</a> /
              <a href="http://arxiv.org/pdf/1604.02647v1.pdf">arxiv</a> /
              <a href="https://www.youtube.com/watch?v=hPksv1gJet4&feature=youtu.be">video</a> /
              <a href="http://www.eccv2016.org/files/posters/P-3C-13.pdf">poster</a> /
              <a href="https://drive.google.com/file/d/0B0J5iCVLyQO9UlhfbEhtOW54cTQ/view">data</a> /
              <a href="">bibtex</a>
              <p>A real-time facial performance capture system from single RGB camera, that is robust to occlusion.</p>
            </td>
          </tr>

        <!-- Service -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          
          <!-- Review -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/reviewer_meme.png" alt="reviewer" width="160" style="border-style: none"></td>
            <td width="75%" valign="center">
              Reviewer <ul>
                <li>NeurIPS 2020, AAAI 2020</li>
                <li>ECCV 2020, CVPR 2020, ICCV 2019, ICCV Workshop PeopleCap 2017</li>
                <li>VRST 2020, Eurographics 2019, Pacific Graphics 2018, CAVW 2018, IEEE VR 2017</li>
              </ul>
              <a href="http://cvpr2020.thecvf.com/reviewer-acknowledgements"><i>Outstanding Reviewer, CVPR 2020</i></a>
            </td>
          </tr>

          <!-- Teaching -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/trojan_logo.jpeg" alt="trojan" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="center">
              Teaching Assistant, CSCI 677 Advanced Computer Vision, Fall 2019
              <br>
              <br>
              Teaching Assistant, <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_teaching_%5BCSCI_621__Digital_Geometry_Processing_SS_2018%5D.html">CSCI 621 Digital Geometry Processing</a>, Spring 2018
              <br>
              <br>
              Grader, EE 559 Mathematical Pattern Recognition, Spring 2015
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center">
                Latest update: Aug 16, 2020.
                <br>
                Wonderful template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
